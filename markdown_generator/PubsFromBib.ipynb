{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a set of bibtex of publications and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). \n",
    "\n",
    "The core python code is also in `pubsFromBibs.py`. \n",
    "Run either from the `markdown_generator` folder after replacing updating the publist dictionary with:\n",
    "* bib file names\n",
    "* specific venue keys based on your bib file preferences\n",
    "* any specific pre-text for specific files\n",
    "* Collection Name (future feature)\n",
    "\n",
    "TODO: Make this work with other databases of citations, \n",
    "TODO: Merge this with the existing TSV parsing solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybtex.database.input import bibtex\n",
    "import pybtex.database.input.bibtex \n",
    "from time import strptime\n",
    "import string\n",
    "import html\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: incorporate different collection types rather than a catch all publications, requires other changes to template\n",
    "publist = {\n",
    "    \"proceeding\": {\n",
    "        \"file\" : \"proceedings.bib\",\n",
    "        \"venuekey\": \"booktitle\",\n",
    "        \"venue-pretext\": \"In the proceedings of \",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "        \n",
    "    },\n",
    "    \"journal\":{\n",
    "        \"file\": \"pubs.bib\",\n",
    "        \"venuekey\" : \"journal\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCESSFULLY PARSED kokcam_meric_2018: \" Meri{\\c c} {Nehri} {Ak{\\i}mlar{\\i}n{\\i}n} {Yapay} {Sinir} {A ... \"\n",
      "SUCESSFULLY PARSED nebioglu_sakarya_2016: \" Sakarya {Uni}?versi?tesi? {Fen} {Bi}?li?mleri? {Ensti}?t{\\\"u ... \"\n",
      "SUCESSFULLY PARSED demir_solving_2016: \" Solving {Process} {Planning}, {ATC} {Scheduling} and {Due}-d ... \"\n",
      "SUCESSFULLY PARSED demir_integrating_2016: \" Integrating {Process} {Planning}, {WATC} {Weighted} {Schedul ... \"\n",
      "SUCESSFULLY PARSED demir_concurrent_2018: \" Concurrent {Solution} of {WATC} {Scheduling} with {WPPW} {Du ... \"\n",
      "SUCESSFULLY PARSED karayel_cok_2018: \" {\\c C}ok kriterli karar verme teknikleri ile en uygun {LNG}  ... \"\n",
      "SUCESSFULLY PARSED demir_integrated_2019: \" Integrated {Process} {Planning}, {Wms} {Dispatching}, {And}  ... \"\n",
      "SUCESSFULLY PARSED demir_determination_2019: \" Determination of {New} {Proper} {Fire} {Station} {Location}  ... \"\n",
      "SUCESSFULLY PARSED demir_solving_2017: \" Solving {Process} {Planning}, {Weighted} {Apparent} {Tardine ... \"\n",
      "SUCESSFULLY PARSED demir_integrating_2016-1: \" Integrating {Process} {Planning}, {WMS} {Dispatching}, and { ... \"\n",
      "SUCESSFULLY PARSED saygili_research_2016: \" A {Research} on {The} {Analysis} of {Attitudes} {Towards} {E ... \"\n",
      "SUCESSFULLY PARSED cerezci_investigation_2017: \" Investigation of {Electromagnetic} {Pollution} {Awareness} { ... \"\n",
      "SUCESSFULLY PARSED cerezci_investigation_2017-1: \" An {Investigation} of {Awareness} {About} {Electromagnetic}  ... \"\n",
      "SUCESSFULLY PARSED demir_integrated_2017: \" Integrated {Process} {Planning} , {WATC} {Dispatching} , and ... \"\n",
      "SUCESSFULLY PARSED demir_solving_2018: \" Solving {Process} {Planning}, {WMS} {Dispatching}, and {WPPW ... \"\n",
      "SUCESSFULLY PARSED yuvali_economic_2022: \" Economic {Analysis} and {Determination} of {Profitability} o ... \"\n",
      "SUCESSFULLY PARSED arslan_transition_2022: \" The {Transition} to {5G} {Project} {In} {The} {Telecommunica ... \"\n",
      "SUCESSFULLY PARSED bayindir_alternative_2021: \" Alternative {Cleaning} {Company} {Selection} {Method} {With} ... \"\n",
      "SUCESSFULLY PARSED alkan_multi-criteria_2021: \" A {Multi}-{Criteria} {Decision} {Making} and {Goal} {Program ... \"\n",
      "SUCESSFULLY PARSED erden_selection_2019: \" Selection of the {Best} {LNG} {Natural} {Gas} {Supplier} wit ... \"\n",
      "SUCESSFULLY PARSED tanyeri_students_2017: \" Students {Profile} {Choosing} {Sakarya} {University} in the  ... \"\n",
      "SUCESSFULLY PARSED demir_solving_2017: \" Solving {Weighted} {Number} of {Operation} {Plus} {Processin ... \"\n",
      "SUCESSFULLY PARSED demir_solving_2018: \" Solving {Process} {Planning}, {Weighted} {Apparent} {Tardine ... \"\n",
      "SUCESSFULLY PARSED demir_solving_2017-1: \" Solving {Process} {Planning} and {Scheduling} with {Number}  ... \"\n",
      "SUCESSFULLY PARSED arslan_project_2017: \" Project {Management} {Application} in {Food} {Machine} {Manu ... \"\n",
      "SUCESSFULLY PARSED erden_investigation_2016: \" Investigation of {The} {Effect} on the {Buying} {Behavior} o ... \"\n",
      "SUCESSFULLY PARSED demir_integrating_2016: \" Integrating {Process} {Planning}, {WMS} {Dispatching}, and { ... \"\n",
      "SUCESSFULLY PARSED erden_fuzzy_2016: \" Fuzzy {Axiomatic} {Design} for {Solving} the {Facility} {Lay ... \"\n",
      "SUCESSFULLY PARSED teke_determining_2017: \" Determining the {Production} {Amounts} in {Textile} {Industr ... \"\n",
      "SUCESSFULLY PARSED erden_two-phase_2016: \" A {Two}-{Phase} {Modeling} with {Genetic} {Algorithm} for {S ... \"\n",
      "SUCESSFULLY PARSED demir_concurrent_2019: \" Concurrent {Solution} of {WATC} {Scheduling} with {WPPW} {Du ... \"\n",
      "SUCESSFULLY PARSED erden_iplik_2016: \" {\\.I}plik {S{\\\"u}rt{\\\"u}nme} {\\\"O}zelliklerinin {\\.I}nceleme ... \"\n",
      "SUCESSFULLY PARSED erden_solving_2018: \" Solving {Process} {Planning}, {ATC} {Scheduling} and {Due}-d ... \"\n",
      "SUCESSFULLY PARSED erden_growth_2015: \" Growth rate factor analysis of {Turkey} using {Grey} system  ... \"\n",
      "SUCESSFULLY PARSED demir_process_2018: \" Process {Planning} and {Scheduling} with {WNOPPT} {Weighted} ... \"\n",
      "SUCESSFULLY PARSED demir_tabu_2021: \" A {Tabu} {Search} and {Hybrid} {Evolutionary} {Strategies} { ... \"\n",
      "SUCESSFULLY PARSED demir_hybrid_2021: \" Hybrid {Evolutionary} {Strategy} and {Simulated} {Annealing} ... \"\n",
      "SUCESSFULLY PARSED erden_modified_2023: \" A modified integer and categorical {PSO} algorithm for solvi ... \"\n",
      "SUCESSFULLY PARSED demir_dynamic_2020: \" Dynamic integrated process planning, scheduling and due-date ... \"\n",
      "SUCESSFULLY PARSED aksangur_evaluation_2022: \" Evaluation of data preprocessing and feature selection proce ... \"\n",
      "SUCESSFULLY PARSED ozsagir_machine_2022: \" Machine learning approaches for prediction of fine-grained s ... \"\n",
      "SUCESSFULLY PARSED koc_green_2021: \" Green {Supply} {Chain} {Management} in the {Context} of {Sus ... \"\n",
      "SUCESSFULLY PARSED eren_predicting_2023: \" Predicting next hour fine particulate matter ({PM2}.5) in th ... \"\n",
      "SUCESSFULLY PARSED erden_solving_2019: \" Solving {Integrated} {Process} {Planning}, {Dynamic} {Schedu ... \"\n",
      "SUCESSFULLY PARSED erden_genetic_2023: \" Genetic algorithm-based hyperparameter optimization of deep  ... \"\n",
      "SUCESSFULLY PARSED demir_integrating_2017: \" Integrating {Process} {Planning}, {WATC} {Weighted} {Schedul ... \"\n"
     ]
    }
   ],
   "source": [
    "for pubsource in publist:\n",
    "    parser = bibtex.Parser()\n",
    "    bibdata = parser.parse_file(publist[pubsource][\"file\"])\n",
    "\n",
    "    #loop through the individual references in a given bibtex file\n",
    "    for bib_id in bibdata.entries:\n",
    "        #reset default date\n",
    "        pub_year = \"1900\"\n",
    "        pub_month = \"01\"\n",
    "        pub_day = \"01\"\n",
    "        \n",
    "        b = bibdata.entries[bib_id].fields\n",
    "        \n",
    "        try:\n",
    "            pub_year = f'{b[\"year\"]}'\n",
    "\n",
    "            #todo: this hack for month and day needs some cleanup\n",
    "            if \"month\" in b.keys(): \n",
    "                if(len(b[\"month\"])<3):\n",
    "                    pub_month = \"0\"+b[\"month\"]\n",
    "                    pub_month = pub_month[-2:]\n",
    "                elif(b[\"month\"] not in range(12)):\n",
    "                    tmnth = strptime(b[\"month\"][:3],'%b').tm_mon   \n",
    "                    pub_month = \"{:02d}\".format(tmnth) \n",
    "                else:\n",
    "                    pub_month = str(b[\"month\"])\n",
    "            if \"day\" in b.keys(): \n",
    "                pub_day = str(b[\"day\"])\n",
    "\n",
    "                \n",
    "            pub_date = pub_year+\"-\"+pub_month+\"-\"+pub_day\n",
    "            \n",
    "            #strip out {} as needed (some bibtex entries that maintain formatting)\n",
    "            clean_title = b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").replace(\" \",\"-\")    \n",
    "\n",
    "            url_slug = re.sub(\"\\\\[.*\\\\]|[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "            url_slug = url_slug.replace(\"--\",\"-\")\n",
    "            \n",
    "            md_filename = (str(pub_date) + \"-\" + url_slug[:60] + \".md\").replace(\"--\",\"-\")\n",
    "            html_filename = (str(pub_date) + \"-\" + url_slug[:60]).replace(\"--\",\"-\")\n",
    "\n",
    "            #Build Citation from text\n",
    "            citation = \"\"\n",
    "\n",
    "            #citation authors - todo - add highlighting for primary author?\n",
    "            #for author in bibdata.entries[bib_id].persons[\"author\"]:\n",
    "            #    citation = citation+\" \"+author.first_names[0]+\" \"+author.last_names[0]+\", \"\n",
    "\n",
    "            #citation title\n",
    "            citation = citation + \"\\\"\" + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + \".\\\"\"\n",
    "\n",
    "            #add venue logic depending on citation type\n",
    "            venue = publist[pubsource][\"venue-pretext\"]+b[publist[pubsource][\"venuekey\"]].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")\n",
    "\n",
    "            citation = citation + \" \" + html_escape(venue)\n",
    "            citation = citation + \", \" + pub_year + \".\"\n",
    "\n",
    "            \n",
    "            ## YAML variables\n",
    "            md = \"---\\ntitle: \\\"\"   + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + '\"\\n'\n",
    "            \n",
    "            md += \"\"\"collection: \"\"\" +  publist[pubsource][\"collection\"][\"name\"]\n",
    "\n",
    "            md += \"\"\"\\npermalink: \"\"\" + publist[pubsource][\"collection\"][\"permalink\"]  + html_filename\n",
    "            \n",
    "            note = False\n",
    "            if \"note\" in b.keys():\n",
    "                if len(str(b[\"note\"])) > 5:\n",
    "                    md += \"\\nexcerpt: '\" + html_escape(b[\"note\"]) + \"'\"\n",
    "                    note = True\n",
    "\n",
    "            md += \"\\ndate: \" + str(pub_date) \n",
    "\n",
    "            md += \"\\nvenue: '\" + html_escape(venue) + \"'\"\n",
    "            \n",
    "            url = False\n",
    "            if \"url\" in b.keys():\n",
    "                if len(str(b[\"url\"])) > 5:\n",
    "                    md += \"\\npaperurl: '\" + b[\"url\"] + \"'\"\n",
    "                    url = True\n",
    "\n",
    "            md += \"\\ncitation: '\" + html_escape(citation) + \"'\"\n",
    "\n",
    "            md += \"\\n---\"\n",
    "\n",
    "            \n",
    "            ## Markdown description for individual page\n",
    "            if note:\n",
    "                md += \"\\n\" + html_escape(b[\"note\"]) + \"\\n\"\n",
    "\n",
    "            if url:\n",
    "                md += \"\\n[Access paper here](\" + b[\"url\"] + \"){:target=\\\"_blank\\\"}\\n\" \n",
    "            else:\n",
    "                md += \"\\nUse [Google Scholar](https://scholar.google.com/scholar?q=\"+html.escape(clean_title.replace(\"-\",\"+\"))+\"){:target=\\\"_blank\\\"} for full citation\"\n",
    "\n",
    "            md_filename = os.path.basename(md_filename)\n",
    "\n",
    "            with open(\"../_publications/\" + md_filename, 'w') as f:\n",
    "                f.write(md)\n",
    "            print(f'SUCESSFULLY PARSED {bib_id}: \\\"', b[\"title\"][:60],\"...\"*(len(b['title'])>60),\"\\\"\")\n",
    "        # field may not exist for a reference\n",
    "        except KeyError as e:\n",
    "            print(f'WARNING Missing Expected Field {e} from entry {bib_id}: \\\"', b[\"title\"][:30],\"...\"*(len(b['title'])>30),\"\\\"\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
